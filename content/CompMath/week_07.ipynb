{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pandas\n",
    "\n",
    "* Pandas is a Python library used for working with data sets.\n",
    "* It has functions for analyzing, cleaning, exploring, and manipulating data.\n",
    "* The name \"Pandas\" has a reference to both \"Panel Data\", and \"Python Data Analysis\" and was created by Wes McKinney in 2008."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "mydataset = {\"cars\": [\"BMW\", \"Volvo\", \"Ford\"], \"passings\": [3, 7, 2]}\n",
    "\n",
    "mydf = pd.DataFrame(mydataset)\n",
    "\n",
    "print(mydf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mydf[\"passings\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A Pandas Series is like a column in a table.\n",
    "\n",
    "It is a one-dimensional array holding data of any type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = [1, 7, 2]\n",
    "myvar = pd.Series(a)\n",
    "print(myvar)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# access the first element\n",
    "print(myvar[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with defined index\n",
    "a = [1, 7, 2]\n",
    "myvar = pd.Series(a, index=[\"x\", \"y\", \"z\"])\n",
    "print(myvar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# access the element with index label\n",
    "print(myvar[\"y\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a series from a dictionary where the keys will be used as index\n",
    "calories = {\"day1\": 420, \"day2\": 380, \"day3\": 390}\n",
    "myvar = pd.Series(calories)\n",
    "print(myvar)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a Series using only data from \"day1\" and \"day2\"\n",
    "calories = {\"day1\": 420, \"day2\": 380, \"day3\": 390}\n",
    "myvar = pd.Series(calories, index=[\"day1\", \"day2\"])\n",
    "print(myvar)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {\"calories\": [420, 380, 390], \"duration\": [50, 40, 45]}\n",
    "df = pd.DataFrame(data)\n",
    "# df = pd.DataFrame(data, index=[\"day1\", \"day2\", \"day3\"])\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loc uses named index\n",
    "print(df.loc[0])\n",
    "# print(df.loc[\"day1\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to include multiple rows\n",
    "print(df.loc[[0, 1]])\n",
    "# print(df.loc[[\"day1\", \"day2\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# iloc for using indexes instead of labels\n",
    "df = pd.DataFrame(data, index=[\"day1\", \"day2\", \"day3\"])\n",
    "print(df.iloc[0:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "data = {\"calories\": [420, 380, 390], \"duration\": [50, 40, 45]}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "selected_df1 = df.loc[[0, 1]]\n",
    "selected_df2 = df.iloc[0:2]\n",
    "\n",
    "print(\n",
    "    f\"The df and selected_df1 share memory using 'loc' method: {np.shares_memory(selected_df1, df)}\"\n",
    ")\n",
    "print(\n",
    "    f\"The df and selected_df2 share memory using 'iloc' method: {np.shares_memory(selected_df2, df)}\"\n",
    ")\n",
    "print(f\"The selected_df1 is a view: {selected_df1._is_view}\")\n",
    "print(f\"The selected_df2 is a view: {selected_df2._is_view}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this behaviour is not guaranteed for mixed data types\n",
    "data = {\n",
    "    \"calories\": [420, 380, 390],\n",
    "    \"duration\": [\"50\", \"40\", \"45\"],\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "selected_df1 = df.loc[[0, 1]]\n",
    "selected_df2 = df.iloc[0:2]\n",
    "\n",
    "print(\n",
    "    f\"The df and selected_df1 share memory using 'loc' method: {np.shares_memory(selected_df1, df)}\"\n",
    ")\n",
    "print(\n",
    "    f\"The df and selected_df2 share memory using 'iloc' method: {np.shares_memory(selected_df2, df)}\"\n",
    ")\n",
    "print(f\"The selected_df1 is a view: {selected_df1._is_view}\")\n",
    "print(f\"The selected_df2 is a view: {selected_df2._is_view}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample data with nan values\n",
    "df = pd.read_csv(\"sample_nan.csv\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check for missing values\n",
    "print(df.isnull())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check for the number of missing values\n",
    "np.sum(df.isnull(), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df[\"point\"].isnull())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sum(df[\"point\"].isnull())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df = df.dropna()\n",
    "new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inplace=True will change the original dataframe\n",
    "df.dropna(inplace=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"sample_nan.csv\")\n",
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fill all missing values with 0\n",
    "df.fillna(0, inplace=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fill missing values specifically for each column\n",
    "df = pd.read_csv(\"sample_nan.csv\")\n",
    "df.fillna({\"name\": \"No Name\", \"point\": 0.0, \"age\": 30.0, \"state\": \"DC\"}, inplace=True)\n",
    "newdf = df[[\"name\", \"point\", \"age\", \"state\"]].copy()\n",
    "newdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data from url\n",
    "url = \"https://github.com/YBI-Foundation/Dataset/raw/refs/heads/main/Diabetes%20Missing%20Data.csv\"\n",
    "df = pd.read_csv(url)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isnull()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isnull().sum(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fill missing values with mean\n",
    "SI_mean = df[\"Serum_Insulin\"].mean()\n",
    "df.fillna({\"Serum_Insulin\": SI_mean}, inplace=True)\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fill missing values with median\n",
    "SF_median = df[\"Skin_Fold\"].median()\n",
    "df.fillna({\"Skin_Fold\": SF_median}, inplace=True)\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fill missing values with mode\n",
    "# mode is the value that appears most frequently\n",
    "BMI_mode = df[\"BMI\"].mode()[0]\n",
    "print(BMI_mode)\n",
    "df.fillna({\"BMI\": BMI_mode}, inplace=True)\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# you can see all mode values\n",
    "df.mode()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Diabetes_Pedigree\"].loc[df[\"Diabetes_Pedigree\"] > 1].info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace all values in \"Diabetes_Pedigree\" column that are greater than 1 with 1\n",
    "df.loc[df[\"Diabetes_Pedigree\"] > 1, \"Diabetes_Pedigree\"] = 1\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# duplicate a row\n",
    "newdf = pd.concat([df, df.iloc[0:1]], ignore_index=True)\n",
    "newdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to check for duplicates\n",
    "# duplicated shows the duplicate rows only\n",
    "newdf.duplicated()\n",
    "# np.sum(newdf.duplicated())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data from url\n",
    "url = \"https://github.com/Opensourcefordatascience/Data-sets/raw/refs/heads/master/automotive_data.csv\"\n",
    "df = pd.read_csv(url)\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sum(df.duplicated())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# number of unique values in each column\n",
    "df.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# unique values in a column\n",
    "df[\"price\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace all \"?\" with \"NaN\"\n",
    "df.replace(\"?\", np.nan, inplace=True)\n",
    "df.dropna(inplace=True)\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert the problematic columns to numeric\n",
    "df[\"price\"] = pd.to_numeric(df[\"price\"])\n",
    "df[\"horsepower\"] = pd.to_numeric(df[\"horsepower\"])\n",
    "df[\"peak-rpm\"] = pd.to_numeric(df[\"peak-rpm\"])\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if you need to discard non-numeric columns\n",
    "newdf = df._get_numeric_data()\n",
    "newdf.info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "newdf.corr().style.background_gradient(cmap=\"coolwarm\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Result of the `corr()` method is a table with a lot of numbers that represents how well the relationship is between two columns.\n",
    "\n",
    "* The number varies from $-1$ to $1$.\n",
    "\n",
    "* $1$ means that there is a 1 to 1 relationship (a perfect correlation), and for this data set, each time a value went up in the first column, the other one went up as well.\n",
    "\n",
    "* $0.9$ is also a good relationship, and if you increase one value, the other will probably increase as well.\n",
    "\n",
    "* $-0.9$ would be just as good relationship as $0.9$, but if you increase one value, the other will probably go down.\n",
    "\n",
    "* $0.2$ means NOT a good relationship, meaning that if one value goes up does not mean that the other will."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
